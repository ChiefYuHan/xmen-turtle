{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmen.knowledge_base import CompositeKnowledgebase\n",
    "from xmen.evaluation import entity_linking_error_analysis, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmen.confhelper import load_config\n",
    "config = load_config('../conf/distemist.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(config.cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_at_k(ground_truth, pred, eval_k=[1,5,8,20,64,100], silent=False):\n",
    "    res = {}\n",
    "    for ki in eval_k:\n",
    "        eval_res = evaluate(ground_truth, pred, top_k_predictions=ki)\n",
    "        if not silent:\n",
    "            print(f'Perf@{ki}', eval_res[\"strict\"]['recall'])\n",
    "        res[ki] = eval_res\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "distemist_gazetteer_jsonl = base_path / 'distemist_gazetteer' / 'distemist_gazetteer.jsonl'\n",
    "\n",
    "dict_configs = ['distemist_gazetteer', 'distemist_umls_es', 'distemist_umls_en_es', 'distemist_umls_all'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset distemist (/home/Florian.Borchert/.cache/huggingface/datasets/bigbio___distemist/distemist_linking_bigbio_kb/1.0.0/f63b2c6775932c342d7bff59d751d6139c0c52c5255f7fbb3e458d255728a8dd)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c15155fb34f466e85d0e009459b65da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bigbio.dataloader import BigBioConfigHelpers\n",
    "import datasets\n",
    "\n",
    "configs = BigBioConfigHelpers()\n",
    "ds = configs.for_config_name('distemist_linking_bigbio_kb').load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Preparation - Just run once\n",
    "\n",
    "__Note__: This is a bit more involved, because we dynamically explore different combinations of DisTEMIST gazetteer and UMLS subsets.\n",
    "\n",
    "In most normal cases, you just want to configure the target dictionary in your .yaml file and run `xmen dict` and `xmen index` with default settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Distemist gazetteer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ../temp; wget https://zenodo.org/record/6505583/files/dictionary_distemist.tsv?download=0 -O ../temp/dictionary_distemist.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup dictionaries\n",
    "\n",
    "TODO!!!!\n",
    "\n",
    "`xmen dict conf/distemist/distemist_gazetteer.yaml --code dicts/distemist.py` OR ``xmen dict conf/distemist.yaml --key distemist_gazetteer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_path = Path(config.dict.distemist_umls_en_es.umls.meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmen.umls import umls_utils\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def read_cui2snomed_mapping(meta_path):\n",
    "    mrconso = 'MRCONSO.RRF'\n",
    "    cui2snomed = defaultdict(list)\n",
    "    headers = umls_utils.read_umls_file_headers(meta_path, mrconso)\n",
    "    with open(f\"{meta_path}/{mrconso}\") as fin:\n",
    "        for line in tqdm(fin.readlines()):\n",
    "            splits = line.strip().split(\"|\")\n",
    "            assert len(headers) == len(splits)\n",
    "            concept = dict(zip(headers, splits))\n",
    "            if concept['SAB'] in ['SNOMEDCT_US', 'SCTSPA']:\n",
    "                cui2snomed[concept['CUI']].append(concept['SCUI'])\n",
    "    return cui2snomed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cui2snomed_mapping = read_cui2snomed_mapping(meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cui2snomed(entry):\n",
    "    res = []\n",
    "    cui = entry['concept_id']\n",
    "    for sctid in cui2snomed_mapping[cui]:\n",
    "        r = entry.copy()\n",
    "        r['concept_id'] = sctid\n",
    "        res.append(r)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def merge_and_write_dicts(target_jsonl, added_jsonl, output_jsonl):\n",
    "    print(f'Writing to {output_jsonl}')\n",
    "    output_jsonl.parent.mkdir(exist_ok=True, parents=True)\n",
    "    cui_count = alias_count = 0\n",
    "    kb = CompositeKnowledgebase([added_jsonl], mappers=[cui2snomed])\n",
    "    with open(output_jsonl, 'w') as fo:\n",
    "        for l in tqdm(list(open(target_jsonl).readlines())):\n",
    "            cui_count += 1\n",
    "            entry = json.loads(l)\n",
    "            sctid = str(entry['concept_id'])\n",
    "            concept = kb.cui_to_entity[sctid]\n",
    "            known_aliases = [entry['canonical_name']] + entry['aliases']\n",
    "            new_aliases = [c for c in [concept.canonical_name] + concept.aliases if c not in known_aliases]\n",
    "            entry['aliases'] += new_aliases\n",
    "            alias_count += len(entry['aliases'])\n",
    "            fo.write(json.dumps(entry) + '\\n')\n",
    "    print(f'Written {cui_count} concepts with {alias_count} aliases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dict_configs[1:]:\n",
    "    merge_and_write_dicts(distemist_gazetteer_jsonl, base_path / d / f'{d}.jsonl', base_path / 'distemist' / 'merged' / f'{d}.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Prepare TF-IDF NGram and SapBERT indices for all configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Run these commands\n",
    "display(Markdown(f\"`xmen index conf/distemist.yaml --dict {base_path / 'distemist_gazetteer' / 'distemist_gazetteer.jsonl'} --output {base_path / 'distemist' / 'merged' / 'distemist_gazetteer'} --all`\"))\n",
    "for d in dict_configs[1:]:\n",
    "    display(Markdown(f\"`xmen index conf/distemist.yaml --dict {base_path / 'distemist' / 'merged' / f'{d}.jsonl'} --output {base_path / 'distemist' / 'merged' / f'{d}'} --all`\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Candidate Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_name = 'cambridgeltl/SapBERT-UMLS-2020AB-all-lang-from-XLMR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_util import analyze\n",
    "from xmen.linkers import TFIDFNGramLinker, SapBERTLinker, EnsembleLinker\n",
    "from xmen.linkers.util import filter_and_apply_threshold\n",
    "from datasets import DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_linkers(dict_config):\n",
    "    index_base_path = base_path / 'distemist' / 'merged' / dict_config / 'index'\n",
    "    \n",
    "    ngram_linker = TFIDFNGramLinker(index_base_path=index_base_path / 'ngrams', k=100)\n",
    "    pred_ngram = ngram_linker.predict_batch(ds)\n",
    "    pred_ngram.save_to_disk(Path('..') / 'temp' / dict_config / 'pred_ngram')\n",
    "    \n",
    "    # Clear singleton to free up memory\n",
    "    SapBERTLinker.clear()\n",
    "    # Initialize linker from config\n",
    "    sapbert_linker = SapBERTLinker(\n",
    "        embedding_model_name = embedding_model_name,\n",
    "        index_base_path = index_base_path / 'sapbert',\n",
    "        k = 1000\n",
    "    )\n",
    "    \n",
    "    pred_sapbert = sapbert_linker.predict_batch(ds, batch_size=128)\n",
    "    pred_sapbert.save_to_disk(Path('..') / 'temp' / dict_config / 'pred_sapbert')\n",
    "    \n",
    "    # Ensemble\n",
    "    ensemble_linker = EnsembleLinker()\n",
    "    ensemble_linker.add_linker('sapbert', sapbert_linker, k=100)\n",
    "    ensemble_linker.add_linker('ngram', ngram_linker, k=100)\n",
    "    \n",
    "    pred_ensemble = DatasetDict()\n",
    "    # TODO: reuse_preds currently does not work with dataset dicts\n",
    "    pred_ensemble['train'] = ensemble_linker.predict_batch(ds['train'], 128, 100, reuse_preds={'sapbert' : pred_sapbert['train'], 'ngram' : pred_ngram['train']})\n",
    "    pred_ensemble['test'] = ensemble_linker.predict_batch(ds['test'], 128, 100, reuse_preds={'sapbert' : pred_sapbert['test'], 'ngram' : pred_ngram['test']})\n",
    "    \n",
    "    pred_ensemble.save_to_disk(Path('..') / 'temp' / dict_config / 'pred_ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dict_configs:\n",
    "    print(d)\n",
    "    run_linkers(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "\n",
    "cg_performance = []\n",
    "\n",
    "for d in dict_configs:\n",
    "    print(d)\n",
    "    print('Ngram')\n",
    "    pred_ngram = datasets.load_from_disk(Path('..') / 'temp' / d / 'pred_ngram')\n",
    "    eval_ngram = evaluate_at_k(ds['train'], pred_ngram['train'])\n",
    "    for k, v in eval_ngram.items():\n",
    "        cg_performance.append({'k' : k, 'linker' : 'ngram', 'dict' : d, 'recall' : v['strict']['recall']})\n",
    "    print('SapBERT')\n",
    "    pred_sapbert = datasets.load_from_disk(Path('..') / 'temp' / d / 'pred_sapbert')\n",
    "    eval_sapbert = evaluate_at_k(ds['train'], filter_and_apply_threshold(pred_sapbert['train'], k=100, threshold=0.0))\n",
    "    for k, v in eval_sapbert.items():\n",
    "        cg_performance.append({'k' : k, 'linker' : 'sapbert', 'dict' : d, 'recall' : v['strict']['recall']})\n",
    "    print('Ensemble')\n",
    "    pred_ensemble = datasets.load_from_disk(Path('..') / 'temp' / d / 'pred_ensemble')\n",
    "    eval_ensemble = evaluate_at_k(ds['train'], pred_ensemble['train'])\n",
    "    for k, v in eval_ensemble.items():\n",
    "        cg_performance.append({'k' : k, 'linker' : 'ensemble', 'dict' : d, 'recall' : v['strict']['recall']})\n",
    "        \n",
    "cg_performance = pd.DataFrame(cg_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_performance.query('k < 100').sort_values('recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmen.reranking.cross_encoder import CrossEncoderReranker, CrossEncoderTrainingArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_RERANKING = 64\n",
    "CONTEXT_LENGTH = 128\n",
    "CROSS_ENC_MODEL = 'cambridgeltl/SapBERT-UMLS-2020AB-all-lang-from-XLMR'\n",
    "NUM_EPOCHS = 10\n",
    "tmp_path = Path('..') / 'temp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Cross-Encoder Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmen.linkers.util import filter_and_apply_threshold\n",
    "\n",
    "candidates = datasets.load_from_disk(tmp_path / 'distemist_umls_en_es' / 'pred_ensemble')\n",
    "candidates = filter_and_apply_threshold(candidates, K_RERANKING, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODxmen.linkers.utilms configurable\n",
    "from xmen.knowledge_base import load_kb\n",
    "kb = load_kb(base_path / 'distemist' / 'merged' / 'distemist_umls_en_es.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_enc_ds = CrossEncoderReranker.prepare_data(candidates, ds, kb, CONTEXT_LENGTH)\n",
    "# TODO: get proper validation set\n",
    "cross_enc_ds['validation'] = cross_enc_ds['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_enc_ds.save_to_disk('../temp/cross_enc_ds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Cross Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': [5136 items], 'test': [2598 items], 'validation': [2598 items]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xmen.data.indexed_dataset import IndexedDatasetDict\n",
    "cross_enc_ds = IndexedDatasetDict.load_from_disk('../temp/cross_enc_ds')\n",
    "cross_enc_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = CrossEncoderTrainingArgs(\n",
    "    CROSS_ENC_MODEL, \n",
    "    NUM_EPOCHS,\n",
    "    score_regularization=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['Distemist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/nfs/home/Florian.Borchert/workspace/xmen/notebooks/wandb/run-20230504_145716-l20tnikv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/phlobo/xmen-notebooks/runs/l20tnikv\" target=\"_blank\">carbonite-shuttle-8</a></strong> to <a href=\"https://wandb.ai/phlobo/xmen-notebooks\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name := cambridgeltl/SapBERT-UMLS-2020AB-all-lang-from-XLMR\n",
      "num_train_epochs := 10\n",
      "fp16 := True\n",
      "label_smoothing := False\n",
      "score_regularization := True\n",
      "train_layers := None\n",
      "softmax_loss := True\n",
      "_timestamp := 1683205039\n",
      "_runtime := 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cambridgeltl/SapBERT-UMLS-2020AB-all-lang-from-XLMR were not used when initializing XLMRobertaForSequenceClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cambridgeltl/SapBERT-UMLS-2020AB-all-lang-from-XLMR and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-04 14:57:23 - Use pytorch device: cuda\n",
      "Using score regularization: True\n",
      "Using label smoothing factor: False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f7b77f3f004719b974fa693dc8cc29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71403a5b54554c7caabd4b13912ee51d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-04 16:11:56 - EntityLinkingEvaluator: Evaluating the model on eval dataset after epoch 0:\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf, SCMode\n",
    "import wandb\n",
    "\n",
    "def wandb_callback(score, epoch, steps):\n",
    "    wandb.log({\n",
    "        \"eval/accuracy\" : score,\n",
    "        \"train/epoch\" : epoch\n",
    "    })\n",
    "    \n",
    "def eval_callback(dic):\n",
    "    wandb.log(dic)\n",
    "\n",
    "try:\n",
    "    with wandb.init(tags=tags) as run:\n",
    "        #dict_config = OmegaConf.to_container(conf, structured_config_mode=SCMode.DICT_CONFIG)\n",
    "        wandb.log(train_args.args)\n",
    "        rr = CrossEncoderReranker()\n",
    "        output_dir = f'{tmp_path}/cross_encoder/{run.name}'\n",
    "        wandb.log({'output_dir' : output_dir})\n",
    "        rr.fit(cross_enc_ds['train'].dataset, cross_enc_ds['validation'].dataset, output_dir=output_dir, training_args=train_args, callback=wandb_callback, eval_callback=eval_callback)\n",
    "finally:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_ngram = CompositeKnowledgebase([Path(config.cache_dir) / 'distemist_gazetteer' / 'distemist_gazetteer.jsonl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ea_ngram = entity_linking_error_analysis(ds['train'], pred_ngram['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ea_df_ngram, ea_counts_ngram = analyze(ea_ngram, kb_ngram, '', sem_group_version=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ea_counts_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_at_k(ds['train'], prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_at_k(ds['train'], prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmen.linkers import EnsembleLinker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = EnsembleLinker()\n",
    "ensemble.add_linker('sap', sap_bert_linker, k=100)\n",
    "ensemble.add_linker('ngram', ngram_linker, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_pred = ensemble.predict_batch(ds, batch_size=128, top_k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_at_k(ds['train'], ensemble_pred['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_pred.save_to_disk('ensemble_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "prediction = datasets.load_from_disk('prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ea = entity_linking_error_analysis(ds['train'], prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb = CompositeKnowledgebase([Path(config.cache_dir) / 'distemist' / 'distemist.jsonl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ea_df, ea_counts = analyze(ea, kb, '', sem_group_version=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ea_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ea_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear singleton to free up memory\n",
    "SapBERTLinker.clear()\n",
    "# Initialize linker from config\n",
    "sap_bert_linker = SapBERTLinker(\n",
    "    embedding_model_name = embedding_model_name,\n",
    "    index_base_path = Path(config.cache_dir) / 'distemist_gazetteer/index/sapbert',\n",
    "    k = k,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_monoling = sap_bert_linker.predict_batch(ds['train'], batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_at_k(ds['train'], prediction_monoling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_at_k(ds['train'], prediction_monoling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry",
   "language": "python",
   "name": "poetry-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
