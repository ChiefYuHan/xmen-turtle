{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmen.evaluation import entity_linking_error_analysis, evaluate_at_k\n",
    "from xmen.linkers.util import filter_and_apply_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmen.confhelper import load_config\n",
    "config = load_config('../conf/distemist.yaml')\n",
    "base_path = Path(config.cache_dir)\n",
    "tmp_path = Path('..') / 'temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/Florian.Borchert/.cache/huggingface/modules/datasets_modules/datasets/distemist/f63b2c6775932c342d7bff59d751d6139c0c52c5255f7fbb3e458d255728a8dd (last modified on Thu Apr 20 13:14:35 2023) since it couldn't be found locally at distemist., or remotely on the Hugging Face Hub.\n",
      "Found cached dataset distemist (/home/Florian.Borchert/.cache/huggingface/datasets/distemist/distemist_linking_bigbio_kb/1.0.0/f63b2c6775932c342d7bff59d751d6139c0c52c5255f7fbb3e458d255728a8dd)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fabc66fa85345cc825133921fccf49a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/Florian.Borchert/.cache/huggingface/datasets/distemist/distemist_linking_bigbio_kb/1.0.0/f63b2c6775932c342d7bff59d751d6139c0c52c5255f7fbb3e458d255728a8dd/cache-c51f74b0be31bc1c.arrow\n",
      "Loading cached processed dataset at /home/Florian.Borchert/.cache/huggingface/datasets/distemist/distemist_linking_bigbio_kb/1.0.0/f63b2c6775932c342d7bff59d751d6139c0c52c5255f7fbb3e458d255728a8dd/cache-2b861d41b461ff1b.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'document_id', 'passages', 'entities', 'events', 'coreferences', 'relations'],\n",
       "        num_rows: 466\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'document_id', 'passages', 'entities', 'events', 'coreferences', 'relations'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'document_id', 'passages', 'entities', 'events', 'coreferences', 'relations'],\n",
       "        num_rows: 117\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "ds = datasets.load_dataset('distemist', 'distemist_linking_bigbio_kb')\n",
    "\n",
    "# Own validation set (20% of distemist training set / EL sub-track)\n",
    "with open('distemist_validation_docs.txt', 'r') as fh:\n",
    "    valid_ids = [l.strip() for l in fh.readlines()]\n",
    "    \n",
    "ds_train = ds['train'].filter(lambda d: d['document_id'] not in valid_ids)\n",
    "ds_valid = ds['train'].filter(lambda d: d['document_id'] in valid_ids)\n",
    "\n",
    "ds['train'] = ds_train\n",
    "ds['validation'] = ds_valid\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preparation - Just run once\n",
    "\n",
    "__Note__: This is a bit more involved, because we dynamically explore different combinations of DisTEMIST gazetteer and UMLS subsets.\n",
    "\n",
    "In most normal cases, you just want to configure the target dictionary in your .yaml file and run `xmen dict` and `xmen index` with default settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Distemist gazetteer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ../temp; wget https://zenodo.org/record/6505583/files/dictionary_distemist.tsv?download=0 -O ../temp/dictionary_distemist.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the DisTEMIST Task only covers a subset of SNOMED CT codes, we retrieve only additional synonyms for the UMLS for these codes.\n",
    "Thus, we need to map CUIs to SNOMED CT IDs and merge them with the DisTEMIST gazetteer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_configs = ['distemist_gazetteer', 'distemist_umls_es', 'distemist_umls_en_es', 'distemist_umls_all'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Run these commands from the root folder\n",
    "for d in dict_configs:\n",
    "    display(Markdown(f\"`xmen dict conf/distemist.yaml --code dicts/distemist.py --key {d}`\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_path = Path(config.umls_meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmen.umls import umls_utils\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def read_cui2snomed_mapping(meta_path):\n",
    "    mrconso = 'MRCONSO.RRF'\n",
    "    cui2snomed = defaultdict(list)\n",
    "    headers = umls_utils.read_umls_file_headers(meta_path, mrconso)\n",
    "    with open(f\"{meta_path}/{mrconso}\") as fin:\n",
    "        for line in tqdm(fin.readlines()):\n",
    "            splits = line.strip().split(\"|\")\n",
    "            assert len(headers) == len(splits)\n",
    "            concept = dict(zip(headers, splits))\n",
    "            if concept['SAB'] in ['SNOMEDCT_US', 'SCTSPA']:\n",
    "                cui2snomed[concept['CUI']].append(concept['SCUI'])\n",
    "    return cui2snomed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cui2snomed_mapping = read_cui2snomed_mapping(meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from xmen.knowledge_base import CompositeKnowledgebase\n",
    "\n",
    "def cui2snomed(entry):\n",
    "    res = []\n",
    "    cui = entry['concept_id']\n",
    "    for sctid in cui2snomed_mapping[cui]:\n",
    "        r = entry.copy()\n",
    "        r['concept_id'] = sctid\n",
    "        res.append(r)\n",
    "    return res\n",
    "\n",
    "def merge_and_write_dicts(target_jsonl, added_jsonl, output_jsonl):\n",
    "    print(f'Writing to {output_jsonl}')\n",
    "    output_jsonl.parent.mkdir(exist_ok=True, parents=True)\n",
    "    cui_count = alias_count = 0\n",
    "    kb = CompositeKnowledgebase([added_jsonl], mappers=[cui2snomed])\n",
    "    with open(output_jsonl, 'w') as fo:\n",
    "        for l in tqdm(list(open(target_jsonl).readlines())):\n",
    "            cui_count += 1\n",
    "            entry = json.loads(l)\n",
    "            sctid = str(entry['concept_id'])\n",
    "            concept = kb.cui_to_entity[sctid]\n",
    "            known_aliases = [entry['canonical_name']] + entry['aliases']\n",
    "            new_aliases = [c for c in [concept.canonical_name] + concept.aliases if c not in known_aliases]\n",
    "            entry['aliases'] += new_aliases\n",
    "            alias_count += len(entry['aliases'])\n",
    "            fo.write(json.dumps(entry) + '\\n')\n",
    "    print(f'Written {cui_count} concepts with {alias_count} aliases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dict_configs[1:]:\n",
    "    merge_and_write_dicts(distemist_gazetteer_jsonl, base_path / d / f'{d}.jsonl', base_path / 'distemist' / 'merged' / f'{d}.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare TF-IDF NGram and SapBERT indices for all configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run these commands from the root folder\n",
    "display(Markdown(f\"`xmen index conf/distemist.yaml --dict {base_path / 'distemist_gazetteer' / 'distemist_gazetteer.jsonl'} --output {base_path / 'distemist' / 'merged' / 'distemist_gazetteer'} --all`\"))\n",
    "for d in dict_configs[1:]:\n",
    "    display(Markdown(f\"`xmen index conf/distemist.yaml --dict {base_path / 'distemist' / 'merged' / f'{d}.jsonl'} --output {base_path / 'distemist' / 'merged' / f'{d}'} --all`\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Candidate Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_name = 'cambridgeltl/SapBERT-UMLS-2020AB-all-lang-from-XLMR'\n",
    "dict_config = 'distemist_umls_en_es'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_util import analyze\n",
    "from xmen.linkers import TFIDFNGramLinker, SapBERTLinker, EnsembleLinker\n",
    "from xmen.linkers.util import filter_and_apply_threshold\n",
    "from datasets import DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_base_path = base_path / 'distemist' / 'merged' / dict_config / 'index'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF over character n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/466 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/466 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ngram_linker = TFIDFNGramLinker(index_base_path=index_base_path / 'ngrams', k=100)\n",
    "pred_ngram = ngram_linker.predict_batch(ds)\n",
    "pred_ngram.save_to_disk(tmp_path / dict_config / 'pred_ngram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf@1 0.28599801390268126\n",
      "Perf@2 0.4141012909632572\n",
      "Perf@4 0.5858987090367428\n",
      "Perf@8 0.6732869910625621\n",
      "Perf@16 0.7209533267130089\n",
      "Perf@32 0.7616683217477657\n",
      "Perf@64 0.7974180734856008\n"
     ]
    }
   ],
   "source": [
    "_ = evaluate_at_k(ds['validation'], pred_ngram['validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense Retrieval with SapBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/08/23 19:13:30] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading hierarchical faiss index                                <a href=\"file:///mnt/nfs/home/Florian.Borchert/workspace/xmen/notebooks/../xmen/linkers/sap_bert_linker.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">sap_bert_linker.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/nfs/home/Florian.Borchert/workspace/xmen/notebooks/../xmen/linkers/sap_bert_linker.py#116\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/08/23 19:13:30]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading hierarchical faiss index                                \u001b]8;id=319479;file:///mnt/nfs/home/Florian.Borchert/workspace/xmen/notebooks/../xmen/linkers/sap_bert_linker.py\u001b\\\u001b[2msap_bert_linker.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=815753;file:///mnt/nfs/home/Florian.Borchert/workspace/xmen/notebooks/../xmen/linkers/sap_bert_linker.py#116\u001b\\\u001b[2m116\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading index from                                                 <a href=\"file:///mnt/nfs/home/Florian.Borchert/workspace/xmen/notebooks/../xmen/linkers/faiss_indexer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">faiss_indexer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/nfs/home/Florian.Borchert/workspace/xmen/notebooks/../xmen/linkers/faiss_indexer.py#73\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">73</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/home/Florian.Borchert/.cache/xmen/distemist/merged/distemist_umls</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">_en_es/index/sapbert/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">embed_faiss_hier.pickle</span>                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading index from                                                 \u001b]8;id=375339;file:///mnt/nfs/home/Florian.Borchert/workspace/xmen/notebooks/../xmen/linkers/faiss_indexer.py\u001b\\\u001b[2mfaiss_indexer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=387763;file:///mnt/nfs/home/Florian.Borchert/workspace/xmen/notebooks/../xmen/linkers/faiss_indexer.py#73\u001b\\\u001b[2m73\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[35m/home/Florian.Borchert/.cache/xmen/distemist/merged/distemist_umls\u001b[0m \u001b[2m                   \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[35m_en_es/index/sapbert/\u001b[0m\u001b[95membed_faiss_hier.pickle\u001b[0m                       \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/08/23 19:13:32] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loaded index of type <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'faiss.swigfaiss.IndexHNSWFlat'</span><span style=\"font-weight: bold\">&gt;</span> and   <a href=\"file:///mnt/nfs/home/Florian.Borchert/workspace/xmen/notebooks/../xmen/linkers/faiss_indexer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">faiss_indexer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/nfs/home/Florian.Borchert/workspace/xmen/notebooks/../xmen/linkers/faiss_indexer.py#75\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">75</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         size <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1518833</span>                                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/08/23 19:13:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loaded index of type \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'faiss.swigfaiss.IndexHNSWFlat'\u001b[0m\u001b[1m>\u001b[0m and   \u001b]8;id=622698;file:///mnt/nfs/home/Florian.Borchert/workspace/xmen/notebooks/../xmen/linkers/faiss_indexer.py\u001b\\\u001b[2mfaiss_indexer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=465372;file:///mnt/nfs/home/Florian.Borchert/workspace/xmen/notebooks/../xmen/linkers/faiss_indexer.py#75\u001b\\\u001b[2m75\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         size \u001b[1;36m1518833\u001b[0m                                                       \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/466 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/466 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clear singleton to free up memory\n",
    "SapBERTLinker.clear()\n",
    "# Initialize linker from config\n",
    "sapbert_linker = SapBERTLinker(\n",
    "    embedding_model_name = embedding_model_name,\n",
    "    index_base_path = index_base_path / 'sapbert',\n",
    "    k = 1000\n",
    ")\n",
    "\n",
    "pred_sapbert = sapbert_linker.predict_batch(ds, batch_size=128)\n",
    "pred_sapbert.save_to_disk(tmp_path / dict_config / 'pred_sapbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf@1 0.3634558093346574\n",
      "Perf@2 0.5243296921549155\n",
      "Perf@4 0.6593843098311817\n",
      "Perf@8 0.7437934458788481\n",
      "Perf@16 0.7864945382323734\n",
      "Perf@32 0.8083416087388282\n",
      "Perf@64 0.8262164846077458\n"
     ]
    }
   ],
   "source": [
    "_ = evaluate_at_k(ds['validation'], pred_sapbert['validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/466 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/466 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ensemble_linker = EnsembleLinker()\n",
    "ensemble_linker.add_linker('sapbert', sapbert_linker, k=100)\n",
    "ensemble_linker.add_linker('ngram', ngram_linker, k=100)\n",
    "\n",
    "# Re-use predictions for efficiency\n",
    "# TODO: reuse_preds currently does not work with dataset dicts\n",
    "pred_ensemble = DatasetDict()\n",
    "pred_ensemble['train'] = ensemble_linker.predict_batch(ds['train'], 128, 100, reuse_preds={'sapbert' : pred_sapbert['train'], 'ngram' : pred_ngram['train']})\n",
    "pred_ensemble['validation'] = ensemble_linker.predict_batch(ds['validation'], 128, 100, reuse_preds={'sapbert' : pred_sapbert['validation'], 'ngram' : pred_ngram['validation']})\n",
    "pred_ensemble['test'] = ensemble_linker.predict_batch(ds['test'], 128, 100, reuse_preds={'sapbert' : pred_sapbert['test'], 'ngram' : pred_ngram['test']})\n",
    "\n",
    "pred_ensemble.save_to_disk(tmp_path / dict_config / 'pred_ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf@1 0.4270109235352532\n",
      "Perf@2 0.5412115193644489\n",
      "Perf@4 0.660377358490566\n",
      "Perf@8 0.7487586891757696\n",
      "Perf@16 0.7954319761668321\n",
      "Perf@32 0.8152929493545183\n",
      "Perf@64 0.8411122144985105\n"
     ]
    }
   ],
   "source": [
    "_ = evaluate_at_k(ds['validation'], pred_ensemble['validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmen.reranking.cross_encoder import CrossEncoderReranker, CrossEncoderTrainingArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_RERANKING = 64\n",
    "CONTEXT_LENGTH = 128\n",
    "CROSS_ENC_MODEL = 'PlanTL-GOB-ES/roberta-base-biomedical-clinical-es'\n",
    "NUM_EPOCHS = 20\n",
    "SEM_TYPE=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Cross-Encoder Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary used for entity representation\n",
    "dict_config_rr = 'distemist_umls_es'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/466 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xmen.linkers.util import filter_and_apply_threshold\n",
    "\n",
    "candidates = datasets.load_from_disk(tmp_path / dict_config / 'pred_ensemble')\n",
    "candidates = filter_and_apply_threshold(candidates, K_RERANKING, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmen.knowledge_base import load_kb\n",
    "#kb = load_kb(base_path / 'distemist_gazetteer' / 'distemist_gazetteer.jsonl')\n",
    "kb = load_kb(base_path / 'distemist' / 'merged' / f'{dict_config_rr}.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context length: 128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221ec36c47c9471db6ad01abea76c9e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2315cab2acf246358b83510f0a905fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e3c176e3094bce960f3bafa2c3fd67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1a82537c8445bab8aece3ad6dd1934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777b853b872a429cb95196e687a9a933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cace64a983e4117950ce3ed7289f07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748b2e26d1a440a8a147aacd9511e601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2598 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660f4fb8b03f4ecf9664f01281aec5ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2598 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7b7ee83efa4fdf8c67eb09f8f7e892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2598 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cross_enc_ds = CrossEncoderReranker.prepare_data(candidates, ds, kb, CONTEXT_LENGTH, encode_sem_type=SEM_TYPE)\n",
    "cross_enc_ds.save_to_disk(tmp_path / f'cross_enc_ds_{dict_config_rr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Cross Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': [4180 items], 'validation': [956 items], 'test': [2598 items]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xmen.data.indexed_dataset import IndexedDatasetDict\n",
    "cross_enc_ds = IndexedDatasetDict.load_from_disk(tmp_path / f'cross_enc_ds_{dict_config_rr}')\n",
    "cross_enc_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ScoredInputExample> label: 0, score: 0.6854951977729797, texts:  dado de alta a los diez días de la intervención quirúrgica.\n",
       " El estudio anatomopatológico del apéndice cecal fue informado como  [START] apéndice cecal con signos inflamatorios [END] \n",
       " \n",
       " ; disorder [TYPE] inflamación de apéndice epiploico [TITLE] inflamación de apéndice epiploico (trastorno) [SEP] Apendicitis epiploica,\n",
       " <ScoredInputExample> label: 0, score: 0.6809297800064087, texts:  dado de alta a los diez días de la intervención quirúrgica.\n",
       " El estudio anatomopatológico del apéndice cecal fue informado como  [START] apéndice cecal con signos inflamatorios [END] \n",
       " \n",
       " ; disorder [TYPE] apendicitis crónica [TITLE] inflamación crónica del apéndice [SEP] apendicitis crónica (trastorno) [SEP] Apendicitis crónica,\n",
       " <ScoredInputExample> label: 0, score: 0.6728464961051941, texts:  dado de alta a los diez días de la intervención quirúrgica.\n",
       " El estudio anatomopatológico del apéndice cecal fue informado como  [START] apéndice cecal con signos inflamatorios [END] \n",
       " \n",
       " ; disorder [TYPE] inflamación de apéndice epiploico debida a isquemia [TITLE] inflamación de apéndice epiploico debida a isquemia (trastorno),\n",
       " <ScoredInputExample> label: 0, score: 0.6708012819290161, texts:  dado de alta a los diez días de la intervención quirúrgica.\n",
       " El estudio anatomopatológico del apéndice cecal fue informado como  [START] apéndice cecal con signos inflamatorios [END] \n",
       " \n",
       " ; disorder [TYPE] apendicitis atípica [TITLE] inflamación atípica del apéndice [SEP] apendicitis atípica (trastorno),\n",
       " <ScoredInputExample> label: 0, score: 0.6643346548080444, texts:  dado de alta a los diez días de la intervención quirúrgica.\n",
       " El estudio anatomopatológico del apéndice cecal fue informado como  [START] apéndice cecal con signos inflamatorios [END] \n",
       " \n",
       " ; disorder [TYPE] apendicitis aguda [TITLE] Acute appendicitis NOS [SEP] apendicitis aguda (trastorno) [SEP] apendicitis aguda, SAI [SEP] Apendicitis aguda [SEP] apendicitis aguda, SAI (trastorno),\n",
       " <ScoredInputExample> label: 0, score: 0.6643346548080444, texts:  dado de alta a los diez días de la intervención quirúrgica.\n",
       " El estudio anatomopatológico del apéndice cecal fue informado como  [START] apéndice cecal con signos inflamatorios [END] \n",
       " \n",
       " ; disorder [TYPE] apendicitis aguda, SAI [TITLE] apendicitis aguda [SEP] Acute appendicitis NOS [SEP] apendicitis aguda (trastorno) [SEP] Apendicitis aguda [SEP] apendicitis aguda, SAI (trastorno),\n",
       " <ScoredInputExample> label: 0, score: 0.6643346548080444, texts:  dado de alta a los diez días de la intervención quirúrgica.\n",
       " El estudio anatomopatológico del apéndice cecal fue informado como  [START] apéndice cecal con signos inflamatorios [END] \n",
       " \n",
       " ; disorder [TYPE] apendicitis aguda, SAI [TITLE] apendicitis aguda [SEP] Acute appendicitis NOS [SEP] apendicitis aguda (trastorno) [SEP] Apendicitis aguda [SEP] apendicitis aguda, SAI (trastorno),\n",
       " <ScoredInputExample> label: 0, score: 0.6624893546104431, texts:  dado de alta a los diez días de la intervención quirúrgica.\n",
       " El estudio anatomopatológico del apéndice cecal fue informado como  [START] apéndice cecal con signos inflamatorios [END] \n",
       " \n",
       " ; disorder [TYPE] apendicitis aguda con peritonitis generalizada [TITLE] apendicitis aguda con peritonitis generalizada (trastorno) [SEP] Apendicitis aguda con peritonitis generalizada,\n",
       " <ScoredInputExample> label: 0, score: 0.6615241765975952, texts:  dado de alta a los diez días de la intervención quirúrgica.\n",
       " El estudio anatomopatológico del apéndice cecal fue informado como  [START] apéndice cecal con signos inflamatorios [END] \n",
       " \n",
       " ; disorder [TYPE] apendicitis aguda con absceso apendicular [TITLE] apendicitis aguda con absceso apendicular (trastorno),\n",
       " <ScoredInputExample> label: 0, score: 0.6500575542449951, texts:  dado de alta a los diez días de la intervención quirúrgica.\n",
       " El estudio anatomopatológico del apéndice cecal fue informado como  [START] apéndice cecal con signos inflamatorios [END] \n",
       " \n",
       " ; disorder [TYPE] apendicitis curada [TITLE] apendicitis curada (trastorno)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_enc_ds['train'].dataset[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = CrossEncoderTrainingArgs(\n",
    "    CROSS_ENC_MODEL, \n",
    "    NUM_EPOCHS,\n",
    "    score_regularization=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = CrossEncoderReranker()\n",
    "output_dir = f'{tmp_path}/cross_encoder_training/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name := PlanTL-GOB-ES/roberta-base-biomedical-clinical-es\n",
      "num_train_epochs := 20\n",
      "fp16 := True\n",
      "label_smoothing := False\n",
      "score_regularization := True\n",
      "train_layers := None\n",
      "softmax_loss := True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at PlanTL-GOB-ES/roberta-base-biomedical-clinical-es were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-biomedical-clinical-es and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using score regularization: True\n",
      "Using label smoothing factor: False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35966e1e1ff4479db68ee7668d0790b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e748341ecc649cda2de0d51cf50f65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/4180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rr.fit(cross_enc_ds['train'].dataset, cross_enc_ds['validation'].dataset, output_dir=output_dir, training_args=train_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = CrossEncoderReranker.load(output_dir, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_enc_pred = cross_encoder_predict(rr, cross_enc_ds['test'], candidates['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_ngram = CompositeKnowledgebase([Path(config.cache_dir) / 'distemist_gazetteer' / 'distemist_gazetteer.jsonl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ea_ngram = entity_linking_error_analysis(ds['train'], pred_ngram['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ea_df_ngram, ea_counts_ngram = analyze(ea_ngram, kb_ngram, '', sem_group_version=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ea_counts_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_at_k(ds['train'], prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_at_k(ds['train'], prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmen.linkers import EnsembleLinker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = EnsembleLinker()\n",
    "ensemble.add_linker('sap', sap_bert_linker, k=100)\n",
    "ensemble.add_linker('ngram', ngram_linker, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_pred = ensemble.predict_batch(ds, batch_size=128, top_k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_at_k(ds['train'], ensemble_pred['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_pred.save_to_disk('ensemble_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "prediction = datasets.load_from_disk('prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ea = entity_linking_error_analysis(ds['train'], prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb = CompositeKnowledgebase([Path(config.cache_dir) / 'distemist' / 'distemist.jsonl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ea_df, ea_counts = analyze(ea, kb, '', sem_group_version=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ea_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ea_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear singleton to free up memory\n",
    "SapBERTLinker.clear()\n",
    "# Initialize linker from config\n",
    "sap_bert_linker = SapBERTLinker(\n",
    "    embedding_model_name = embedding_model_name,\n",
    "    index_base_path = Path(config.cache_dir) / 'distemist_gazetteer/index/sapbert',\n",
    "    k = k,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_monoling = sap_bert_linker.predict_batch(ds['train'], batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_at_k(ds['train'], prediction_monoling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_at_k(ds['train'], prediction_monoling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry",
   "language": "python",
   "name": "poetry-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
